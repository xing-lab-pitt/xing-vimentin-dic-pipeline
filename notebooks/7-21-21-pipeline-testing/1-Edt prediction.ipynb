{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "through-international",
   "metadata": {},
   "source": [
    "# Selecting a small set of images for prepare icnn\n",
    "\n",
    "I croped dld1 cells from the 06-21-21 B1_02 position. The image series contains more than a thousand pictures. So I'll pick 30 frame. The selected images are stored at:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "interim-elevation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model path: ./models/dld1.hdf5 use binary? (if false then edt applied): False\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 14419927559658735301\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 8928855383738458738\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "# These top lines are critical for import from another folder\n",
    "sys.path.insert(1, '/net/capricorn/home/xing/huijing/Segmentation/scripts/Image_analysis_pipeline_vim_dic/')\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from cnn_prep_data import prep_icnn_am_train_data\n",
    "import pipe_1_img_edt as p1_edt\n",
    "import train_icnn_am\n",
    "import sbatch_jobs\n",
    "import pipe_util2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "united-carol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/net/capricorn/home/xing/huijing/Segmentation/scripts/Image_analysis_pipeline_vim_dic/7-21-21-pipeline-testing/sample_data/06-21-21-B1_02_crop_part_30_output'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2_folder = \"./sample_data/06-21-21-B1_02_crop_part_30/\"\n",
    "b2_folder = os.path.abspath(b2_folder) # using abs path is critical, especially for sbatch jobs.\n",
    "\n",
    "b2_output = pipe_util2.folder_verify(b2_folder)[:-1]+ \"_output\"\n",
    "\n",
    "weight = \"./sample_data/models/imgseg_weights/7-21-21-dld1_edt_fcn_add1_ep100.hdf5\"\n",
    "weight = os.path.abspath(weight) \n",
    "\n",
    "mode = \"reg_seg\"\n",
    "\n",
    "b2_output\n",
    "# b2_train_folder = \"./sample_data/06-21-21-B1_02_crop_part_30_seg_main/\" # training data for edt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-damage",
   "metadata": {},
   "source": [
    "# Create edt for the img folder (python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "external-omaha",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /net/capricorn/home/xing/huijing/.conda/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /net/capricorn/home/xing/huijing/.conda/envs/tf1/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "/net/capricorn/home/xing/huijing/Segmentation/scripts/Image_analysis_pipeline_vim_dic/7-21-21-pipeline-testing/sample_data/06-21-21-B1_02_crop_part_30_output/edt/ folder is freshly created. \n",
      "\n",
      "/net/capricorn/home/xing/huijing/Segmentation/scripts/Image_analysis_pipeline_vim_dic/7-21-21-pipeline-testing/sample_data/06-21-21-B1_02_crop_part_30/VID99_B1_2_00d00h00m.tif\n",
      "WARNING:tensorflow:From /net/capricorn/home/xing/huijing/.conda/envs/tf1/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "1.7913151 0.0\n",
      "1.7779964 0.0\n",
      "output dim:  (539, 520)\n",
      "/net/capricorn/home/xing/huijing/Segmentation/scripts/Image_analysis_pipeline_vim_dic/7-21-21-pipeline-testing/sample_data/06-21-21-B1_02_crop_part_30/VID99_B1_2_00d04h05m.tif\n",
      "1.5228739 0.0\n",
      "1.5151547 0.0\n",
      "output dim:  (539, 520)\n",
      "/net/capricorn/home/xing/huijing/Segmentation/scripts/Image_analysis_pipeline_vim_dic/7-21-21-pipeline-testing/sample_data/06-21-21-B1_02_crop_part_30/VID99_B1_2_00d08h15m.tif\n",
      "1.607254 0.0\n",
      "1.5947832 0.0\n",
      "output dim:  (539, 520)\n",
      "/net/capricorn/home/xing/huijing/Segmentation/scripts/Image_analysis_pipeline_vim_dic/7-21-21-pipeline-testing/sample_data/06-21-21-B1_02_crop_part_30/VID99_B1_2_00d12h20m.tif\n",
      "1.9017262 0.0\n",
      "1.8944037 0.0\n",
      "output dim:  (539, 520)\n",
      "/net/capricorn/home/xing/huijing/Segmentation/scripts/Image_analysis_pipeline_vim_dic/7-21-21-pipeline-testing/sample_data/06-21-21-B1_02_crop_part_30/VID99_B1_2_00d16h30m.tif\n",
      "1.847711 0.0\n",
      "1.827505 0.0\n",
      "output dim:  (539, 520)\n",
      "/net/capricorn/home/xing/huijing/Segmentation/scripts/Image_analysis_pipeline_vim_dic/7-21-21-pipeline-testing/sample_data/06-21-21-B1_02_crop_part_30/VID99_B1_2_00d20h35m.tif\n",
      "1.6248567 0.0\n",
      "1.6112391 0.0\n",
      "output dim:  (539, 520)\n",
      "/net/capricorn/home/xing/huijing/Segmentation/scripts/Image_analysis_pipeline_vim_dic/7-21-21-pipeline-testing/sample_data/06-21-21-B1_02_crop_part_30/VID99_B1_2_01d00h45m.tif\n",
      "2.1442947 0.0\n",
      "2.1362357 0.0\n",
      "output dim:  (539, 520)\n",
      "/net/capricorn/home/xing/huijing/Segmentation/scripts/Image_analysis_pipeline_vim_dic/7-21-21-pipeline-testing/sample_data/06-21-21-B1_02_crop_part_30/VID99_B1_2_01d04h55m.tif\n",
      "1.8865596 0.0\n",
      "1.8714871 0.0\n",
      "output dim:  (539, 520)\n",
      "/net/capricorn/home/xing/huijing/Segmentation/scripts/Image_analysis_pipeline_vim_dic/7-21-21-pipeline-testing/sample_data/06-21-21-B1_02_crop_part_30/VID99_B1_2_01d09h00m.tif\n",
      "1.7082902 0.0\n",
      "1.6897126 0.0\n",
      "output dim:  (539, 520)\n",
      "/net/capricorn/home/xing/huijing/Segmentation/scripts/Image_analysis_pipeline_vim_dic/7-21-21-pipeline-testing/sample_data/06-21-21-B1_02_crop_part_30/VID99_B1_2_01d13h10m.tif\n",
      "1.6189016 0.0\n",
      "1.607116 0.0\n",
      "output dim:  (539, 520)\n",
      "/net/capricorn/home/xing/huijing/Segmentation/scripts/Image_analysis_pipeline_vim_dic/7-21-21-pipeline-testing/sample_data/06-21-21-B1_02_crop_part_30/VID99_B1_2_01d17h15m.tif\n",
      "1.7481395 0.0\n",
      "1.7455516 0.0\n",
      "output dim:  (539, 520)\n",
      "/net/capricorn/home/xing/huijing/Segmentation/scripts/Image_analysis_pipeline_vim_dic/7-21-21-pipeline-testing/sample_data/06-21-21-B1_02_crop_part_30/VID99_B1_2_01d21h25m.tif\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-d4a8c689fb56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# weight file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# model_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mp1_edt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfolder_edt_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb2_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Segmentation/scripts/Image_analysis_pipeline_vim_dic/pipe_1_img_edt.py\u001b[0m in \u001b[0;36mfolder_edt_predict\u001b[0;34m(input_folder, output_folder, weight_file, model_mode)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m#print(img.shape, img[np.newaxis,:])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;31m#return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# the img adding a axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf1/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1462\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/.conda/envs/tf1/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.conda/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# input folder\n",
    "# output folder\n",
    "# weight file\n",
    "# model_mode\n",
    "p1_edt.folder_edt_predict(b2_folder, b2_output, weight, mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-wisdom",
   "metadata": {},
   "source": [
    "# Create edt for images (sbatch job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "frozen-current",
   "metadata": {},
   "outputs": [],
   "source": [
    "scr_folder = \"./scripts\"\n",
    "#pipe_util2.create_folder(scr_folder) # create the folder if not exist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-greece",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "\n",
    "Go to sbatch_jobs.py, for each `sbatch_file` function, change the package path to your own absolute package path. Otherwise, the sbatch job may not able to call the correct script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cubic-dispatch",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"0621B2_p\"\n",
    "sbatch_jobs.sbatch_job_1_edt(\n",
    "    scr_folder, \n",
    "    b2_folder, b2_output, \n",
    "    weight, mode,\n",
    "    name = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-socket",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
