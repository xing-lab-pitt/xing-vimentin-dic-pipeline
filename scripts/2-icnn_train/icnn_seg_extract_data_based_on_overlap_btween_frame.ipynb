{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "''' this is for prepare training data of identification CNN on oversegmentation and undersegmentation'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import euclidean,cosine\n",
    "import math\n",
    "from math import pi\n",
    "import scipy\n",
    "from skimage.io import imread\n",
    "from skimage.measure import label,regionprops\n",
    "from skimage.color import label2rgb\n",
    "from skimage import morphology\n",
    "from os import listdir\n",
    "from PIL import Image, ImageDraw,ImageFont\n",
    "from matplotlib import pyplot as plt\n",
    "from pilutil import toimage\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_num='xy01'\n",
    "\n",
    "dir_path='C:/Users/zoro/Desktop/tracking_work/2018-05-18_HK2_dic_cell_cycle/'+pos_num\n",
    "ori_img_path=dir_path+'/img'\n",
    "seg_img_path=dir_path+'/seg'\n",
    "crop_path=dir_path+'/crop'\n",
    "\n",
    "\n",
    "ori_img_list=sorted(listdir(ori_img_path))\n",
    "seg_img_list=sorted(listdir(seg_img_path))\n",
    "df = pd.read_csv(dir_path + '/Per_Object.csv')\n",
    "relation_df=pd.read_csv(dir_path + '/Per_Relationships.csv')\n",
    "am_record=pd.read_csv(dir_path+'/am_record.csv')\n",
    "t_span=max(df['ImageNumber'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fuse_pairs=[]\n",
    "tofuse_cells=[]\n",
    "fused_cells=[]#include: img_num,obj_num,amount of cells fused in this cell\n",
    "\n",
    "\n",
    "split_pairs=[]\n",
    "tosplit_cells=[]##include: img_num,obj_num,amount of cells split from this cell\n",
    "splited_cells=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_overlap_matrix(img_path,img_list,img_num_1,img_num_2):\n",
    "    frame_1=imread(img_path+'/'+img_list[img_num_1-1]) # mask\n",
    "    frame_2=imread(img_path+'/'+img_list[img_num_2-1]) # img\n",
    "    nb_cell_1=np.amax(frame_1)\n",
    "    nb_cell_2=np.amax(frame_2)\n",
    "\n",
    "    frame_overlap=np.zeros((nb_cell_1,nb_cell_2))\n",
    "    for obj_idx1 in range(nb_cell_1):\n",
    "        obj_num1=obj_idx1+1\n",
    "        sc_img=(frame_1==obj_num1) # The mask\n",
    "        ol_judge=np.logical_and(sc_img,frame_2) # croping the cell\n",
    "        ol_value=np.multiply(ol_judge,frame_2)\n",
    "        ol_obj2=np.unique(ol_value).tolist()\n",
    "        #ol_obj2=ol_obj2[ol_obj2!=0]\n",
    "        ol_obj2.remove(0)\n",
    "        if len(ol_obj2)>0:\n",
    "            for obj_num2 in ol_obj2:\n",
    "                ol_area=np.sum(ol_value==obj_num2)\n",
    "                obj_idx2=obj_num2-1\n",
    "                frame_overlap[obj_idx1][obj_idx2]=ol_area  \n",
    "\n",
    "    return frame_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_single_cell_img(img,seg_img,img_num,obj_num,crop_path):      \n",
    "    #single_obj_img=morphology.binary_dilation(seg_img==obj_num,morphology.diamond(16))\n",
    "    single_obj_img=seg_img==obj_num\n",
    "    single_obj_img=label(single_obj_img)\n",
    "    rps=regionprops(single_obj_img)\n",
    "    candi_r=[r for r in rps if r.label==1][0]\n",
    "    candi_box=candi_r.bbox        \n",
    "    single_cell_img=single_obj_img*img\n",
    "    crop_cell_img=single_cell_img[candi_box[0]:candi_box[2],candi_box[1]:candi_box[3]]\n",
    "#     inds=ndimage.distance_transform_edt(crop_cell_img==0, return_distances=False, return_indices=True)\n",
    "#     crop_cell_img=crop_cell_img[tuple(inds)]\n",
    "\n",
    "    cell_img=toimage(crop_cell_img,high=np.max(crop_cell_img),low=np.min(crop_cell_img),mode='I')\n",
    "    cell_img.save(crop_path+'/i'+str(img_num)+'_o'+str(obj_num)+'.tif')\n",
    "    \n",
    "#     re_candi_box=(candi_box[1],candi_box[0],candi_box[3],candi_box[2])\n",
    "#     candi_obj=pil_img.crop(re_candi_box)\n",
    "#     candi_obj.save(crop_path+'/box_i'+str(img_num)+'_o'+str(obj_num)+'.tif')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zoro\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: `toimage` is deprecated!\n",
      "`toimage` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use Pillow's ``Image.fromarray`` directly instead.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "#----------------select obj------------------\n",
    "img_num_1=127\n",
    "obj_num=79\n",
    "img_1=imread(ori_img_path+'/'+ori_img_list[img_num_1-1])\n",
    "seg_img_1=imread(seg_img_path+'/'+seg_img_list[img_num_1-1])\n",
    "generate_single_cell_img(img_1,seg_img_1,img_num_1,obj_num,crop_path)\n",
    "# crop_img=imread(crop_path+'/i1_o5.tif')\n",
    "# plt.imshow(crop_img)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zoro\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: `toimage` is deprecated!\n",
      "`toimage` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use Pillow's ``Image.fromarray`` directly instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#----------------single cell------------------\n",
    "img_num_1=45\n",
    "img_1=imread(ori_img_path+'/'+ori_img_list[img_num_1-1])\n",
    "seg_img_1=imread(seg_img_path+'/'+seg_img_list[img_num_1-1])\n",
    "max_obj_num=np.amax(seg_img_1)\n",
    "for obj_num in range(1,max_obj_num+1):\n",
    "    generate_single_cell_img(img_1,seg_img_1,img_num_1,obj_num,crop_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i_n=29\n",
    "for img_num in range(i_n,i_n+1):\n",
    "    if img_num==t_span:\n",
    "        break\n",
    "    img_num_1=img_num\n",
    "    img_num_2=img_num+1\n",
    "    img_1=imread(ori_img_path+'/'+ori_img_list[img_num_1-1])\n",
    "    img_2=imread(ori_img_path+'/'+ori_img_list[img_num_2-1])\n",
    "    pil_img_1=Image.open(ori_img_path+'/'+ori_img_list[img_num_1-1])\n",
    "    pil_img_2=Image.open(ori_img_path+'/'+ori_img_list[img_num_2-1])\n",
    "    \n",
    "    seg_img_1=imread(seg_img_path+'/'+seg_img_list[img_num_1-1])\n",
    "    seg_img_2=imread(seg_img_path+'/'+seg_img_list[img_num_2-1])\n",
    "    \n",
    "    \n",
    "    frame_overlap=compute_overlap_matrix(seg_img_path,seg_img_list,img_num_1,img_num_2)\n",
    "    area_arr=df.loc[(df['ImageNumber']==img_num_1),'Cell_AreaShape_Area'].values\n",
    "    area_arr_R=df.loc[(df['ImageNumber']==img_num_2),'Cell_AreaShape_Area'].values\n",
    "    \n",
    "\n",
    "    \n",
    "    nb_cell_1=frame_overlap.shape[0]\n",
    "    nb_cell_2=frame_overlap.shape[1]\n",
    "    \n",
    "    #-------calculate the cell merge --------------\n",
    "    frame_fusion = np.zeros(frame_overlap.shape)\n",
    "    for source_o_n in range(1,nb_cell_1+1):\n",
    "        ol_target=frame_overlap[source_o_n-1,:]\n",
    "        if np.all(ol_target==0):#if source obj have no overlap target\n",
    "            target_o_n=0    \n",
    "        else:      \n",
    "            target_o_n=np.argmax(frame_overlap,axis=1)[source_o_n-1]+1\n",
    "        \n",
    "       \n",
    "        if target_o_n> 0:\n",
    "            frame_fusion[source_o_n-1, target_o_n-1] = 1\n",
    "    \n",
    "        \n",
    "\n",
    "    # remove any columns with a single lingering value\n",
    "    S = np.sum(frame_fusion>0,axis=0)\n",
    "    frame_fusion[:, S==1] = 0\n",
    "    \n",
    "        \n",
    "    # Update the sum vector\n",
    "    S = np.sum(frame_fusion, axis=0)\n",
    "    \n",
    "\n",
    "\n",
    "    #Find the fused cell regions number\n",
    "#    fused_cells = np.where(S >= 2)[0]+1\n",
    "#     print(fused_cells)\n",
    "    for i in range(len(np.where(S >= 2)[0])):\n",
    "        print(img_num_2,np.where(S >= 2)[0][i]+1,'fused')\n",
    "        fused_cells.append([img_num_2,np.where(S >= 2)[0][i]+1,S[np.where(S >= 2)[0][i]]])\n",
    "        generate_single_cell_img(img_2,seg_img_2,img_num_2,np.where(S >= 2)[0][i]+1,crop_path)\n",
    "    for i in range(len(np.where(frame_fusion==1)[0])):\n",
    "        fused_pairs.append([img_num_1,np.where(frame_fusion==1)[0][i]+1,img_num_2,np.where(frame_fusion==1)[1][i]+1])\n",
    "        tofuse_cells.append([img_num_1,np.where(frame_fusion==1)[0][i]+1])\n",
    "        print(img_num_1,np.where(frame_fusion==1)[0][i]+1,'to_fuse')\n",
    "        generate_single_cell_img(img_1,seg_img_1,img_num_1,np.where(frame_fusion==1)[0][i]+1,crop_path)\n",
    "    \n",
    "    #print(fused_pairs)\n",
    "    \n",
    "#     #If we didn't find any fusion cases, return\n",
    "#     if np.all(S < 2):\n",
    "#         continue\n",
    "#------------------------------calculate cell split --------------------------\n",
    "    frame_overlap_R=np.transpose(frame_overlap)\n",
    "    frame_split = np.zeros(frame_overlap_R.shape)\n",
    "    for source_R_o_n in range(1,nb_cell_2+1):\n",
    "        ol_target_R=frame_overlap_R[source_R_o_n-1,:]\n",
    "        if np.all(ol_target_R==0):#if source_R obj have no overlap target_R\n",
    "            target_R_o_n=0    \n",
    "        else:      \n",
    "            target_R_o_n=np.argmax(frame_overlap_R,axis=1)[source_R_o_n-1]+1\n",
    "        \n",
    "       \n",
    "        if target_R_o_n> 0:\n",
    "            frame_split[source_R_o_n-1, target_R_o_n-1] = 1\n",
    "    \n",
    "          \n",
    "\n",
    "    # remove any columns with a single lingering value\n",
    "    S = np.sum(frame_split>0,axis=0)\n",
    "    frame_split[:, S==1] = 0\n",
    "    \n",
    "    # Update the sum vector\n",
    "    S = np.sum(frame_split, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "    #Find the fused cell regions number\n",
    "#     split_cells = np.where(S >= 2)[0]+1\n",
    "#     print(split_cells)\n",
    "    for i in range(len(np.where(S >= 2)[0])):\n",
    "        tosplit_cells.append([img_num_1,np.where(S >= 2)[0][i]+1,S[np.where(S >= 2)[0][i]]])\n",
    "        print(img_num_1,np.where(S >= 2)[0][i]+1,'tosplit')\n",
    "        generate_single_cell_img(img_1,seg_img_1,img_num_1,np.where(S >= 2)[0][i]+1,crop_path)\n",
    "    for i in range(len(np.where(frame_split==1)[0])):\n",
    "        split_pairs.append([img_num_1,np.where(frame_split==1)[1][i]+1,img_num_2,np.where(frame_split==1)[0][i]+1])\n",
    "        splited_cells.append([img_num_2,np.where(frame_split==1)[0][i]+1])\n",
    "        print(img_num_2,np.where(frame_split==1)[0][i]+1,'splited')\n",
    "        generate_single_cell_img(img_2,seg_img_2,img_num_2,np.where(frame_split==1)[0][i]+1,crop_path)\n",
    "    #print(split_pairs)\n",
    "    \n",
    "#     #If we didn't find any split cases, return\n",
    "#     if np.all(S < 2):\n",
    "#         continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
